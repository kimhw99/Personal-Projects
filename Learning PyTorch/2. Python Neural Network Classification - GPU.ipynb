{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866542c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types of Classifications\n",
    "#    - Binary Classification (is this spam or not?)\n",
    "#    - Multi Class Classification (is this a photo of sushi, steak or pizza?)\n",
    "#    - Multi Label Classification (what tags should this article have?)\n",
    "#    - https://www.learnpytorch.io/02_pytorch_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d0ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture of a Classification Neural Network\n",
    "\n",
    "#    - Input Layer Shape (Same as number of features)\n",
    "#    - Hidden Layers\n",
    "#    - Neurons per Hidden Layer\n",
    "#    - Output Layer Shape\n",
    "#    - Hidden Layer Activation (usually ReLU)\n",
    "#    - Output Activation (Sigmoid)\n",
    "#    - Loss Function (Binary Crossentropy - torch.nn.BCELoss)\n",
    "#    - Optimizer (SGD - Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0dadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ready Classification Data\n",
    "\n",
    "data = pd.read_csv('IRIS.csv') # import dataframe as pandas\n",
    "#data.replace(\"Iris-setosa\", 0, inplace=True)\n",
    "#data.replace(\"Iris-versicolor\", 1, inplace=True)\n",
    "#data.replace(\"Iris-virginica\", 2, inplace=True)\n",
    "\n",
    "datanp = data.to_numpy() # convert pandas to numpy, shuffle data\n",
    "\n",
    "x = np.zeros((150, 3), dtype=int)\n",
    "datanp = np.concatenate([datanp, x], axis=1)\n",
    "\n",
    "datanp[datanp[:, 4] == 'Iris-setosa', 5] = 1\n",
    "datanp[datanp[:, 4] == 'Iris-versicolor', 6] = 1\n",
    "datanp[datanp[:, 4] == 'Iris-virginica', 7] = 1\n",
    "\n",
    "np.random.shuffle(datanp)\n",
    "\n",
    "# Split into testing, training data & convert to PyTorch Tensors\n",
    "trainX, trainY, testX, testY = datanp[0:140, 0:4].astype('float32'), datanp[0:140, 5:8].astype('float32'), datanp[140:, 0:4].astype('float32'), datanp[140:, 5:8].astype('float32')\n",
    "trainX, trainY, testX, testY = torch.from_numpy(trainX).to(device), torch.from_numpy(trainY).to(device), torch.from_numpy(testX).to(device), torch.from_numpy(testY).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d28921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build a Model\n",
    "\n",
    "\n",
    "# 1. Set up device agnostic code (CPU or GPU if Available)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 2. Construct Model using nn.model\n",
    "\n",
    "class sepalClassifier(nn.Module): # Option 1: Use nn.Module Class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=4, out_features=8) \n",
    "        self.layer_2 = nn.Linear(in_features=8, out_features=8)\n",
    "        self.layer_3 = nn.Linear(in_features=8, out_features=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        # 4 -> 8 -> 8 -> 3\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "\n",
    "model_0 = sepalClassifier().to(device)\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "model_0 = nn.Sequential( # Option 2: use nn.Sequential\n",
    "    nn.Linear(in_features=4, out_features=6),\n",
    "    nn.Linear(in_features=6, out_features=1)).to(device)\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# 3. Define Loss Function & Optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2439a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train & Test Loop\n",
    "epochs = 2000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "\n",
    "    model_0.train()                    # Put model in training mode (this is the default state of a model)\n",
    "\n",
    "    y_pred = model_0(trainX)           # 1. Forward pass on train data using the forward() method inside \n",
    "    loss = loss_fn(y_pred, trainY)     # 2. Calculate the loss (how different are our models predictions to the ground truth)    \n",
    "    optimizer.zero_grad()              # 3. Zero grad (Reset) of the optimizer\n",
    "    loss.backward()                    # 4. Loss backwards\n",
    "    optimizer.step()                   # 5. Progress the optimizer\n",
    "\n",
    "    \n",
    "    \n",
    "    ### Testing\n",
    "    \n",
    "    model_0.eval()                     # Put the model in evaluation mode\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      test_pred = model_0(testX)                                  # 1. Forward pass on test data\n",
    "      test_loss = loss_fn(test_pred, testY)     # 2. Caculate loss on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d900b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9970, 0.0030, 0.0000],\n",
       "        [0.0000, 0.2800, 0.7200],\n",
       "        [0.9900, 0.0100, 0.0000],\n",
       "        [0.0000, 0.0770, 0.9230],\n",
       "        [0.0000, 0.0030, 0.9970],\n",
       "        [0.0000, 0.9330, 0.0670],\n",
       "        [0.0000, 0.0660, 0.9340],\n",
       "        [0.0000, 0.0210, 0.9790],\n",
       "        [0.0010, 0.8590, 0.1400],\n",
       "        [0.0020, 0.9890, 0.0090]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax - Prediction Probabilities\n",
    "torch.softmax(test_pred, dim=1)\n",
    "torch.round(torch.softmax(test_pred, dim=1), decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eacd09cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a6e427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

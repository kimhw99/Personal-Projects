{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46db5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17671dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Workflow\n",
    "#    1: \"data (prepare and load)\",\n",
    "#    2: \"build model\",\n",
    "#    3: \"fitting the model to data (training)\",\n",
    "#    4: \"making predictions and evaluating a model (inference)\",\n",
    "#    5: \"saving and loading a model\",\n",
    "#    6: \"putting it all together\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a948463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Train & Load\n",
    "\n",
    "data = pd.read_csv('IRIS.csv') # import dataframe as pandas\n",
    "\n",
    "datanp = data.to_numpy() # convert pandas to numpy, shuffle data\n",
    "np.random.shuffle(datanp) \n",
    "\n",
    "# Split into testing, training data & convert to PyTorch Tensors\n",
    "trainX, trainY, testX, testY = datanp[0:140, 0:3].astype('float32'), datanp[0:140, 3].astype('float32'), datanp[140:, 0:3].astype('float32'), datanp[140:, 3].astype('float32')\n",
    "trainX, trainY, testX, testY = torch.from_numpy(trainX), torch.from_numpy(trainY), torch.from_numpy(testX), torch.from_numpy(testY)\n",
    "testY = testY.reshape(10, 1)\n",
    "trainY = trainY.reshape(140, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a8b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Build Model\n",
    "    \n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.weights = nn.Parameter(torch.randn(3, 1, dtype=torch.float, requires_grad=True))\n",
    "        self.bias = nn.Parameter(torch.randn(1, dtype=torch.float, requires_grad=True))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.matmul(x, self.weights) + self.bias\n",
    "    \n",
    "# 1 - Almost everything in PyTorch is a nn.Module (think of this as neural network lego blocks)\n",
    "# 2 - Start with random weights & biases, update with gradient descent\n",
    "# 3 - \"x\" is the input data (e.g. training/testing features)\n",
    "\n",
    "# - nn.Module: contains the larger building blocks (layers)\n",
    "# - nn,Parameter: contains the smaller parameters like weights and biases (put these together to make nn.Module(s))\n",
    "# - torch.optim: contains optimization methods on how to improve the parameters within nn.Parameter to better represent input data\n",
    "# - def forward(): tells the larger blocks how to make calculations on inputs (tensors full of data) within nn.Module(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110460c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.3367],\n",
       "         [0.1288],\n",
       "         [0.2345]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2303], requires_grad=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set manual seed since nn.Parameter are randomly initialzied\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s))\n",
    "model_0 = LinearRegression()\n",
    "\n",
    "# Check the nn.Parameter(s) within the nn.Module subclass we created\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe27ebf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights',\n",
       "              tensor([[0.3367],\n",
       "                      [0.1288],\n",
       "                      [0.2345]])),\n",
       "             ('bias', tensor([0.2303]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List named parameters \n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04048e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Training & Testing\n",
    "\n",
    "# Training Loop\n",
    "#    1. Forward Pass\n",
    "#    2. Calculate Loss\n",
    "#    3. Zero Gradients\n",
    "#    4. Perform Backpropogation\n",
    "#    5. Update Optimizer\n",
    "\n",
    "# Testing Loop\n",
    "#    1. Forward Pass\n",
    "#    2. Calculate the Loss\n",
    "#    3. Calculate Evaluation Metrics (Optional)\n",
    "\n",
    "# Create the loss function\n",
    "loss_fn = nn.L1Loss() # MAE loss is same as L1Loss\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01) \n",
    "# learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b11a62a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train Loss: 2.2854599952697754 | MAE Test Loss: 1.5164395570755005 \n",
      "Epoch: 10 | MAE Train Loss: 0.3803354501724243 | MAE Test Loss: 0.3829319477081299 \n",
      "Epoch: 20 | MAE Train Loss: 0.28623056411743164 | MAE Test Loss: 0.3263406753540039 \n",
      "Epoch: 30 | MAE Train Loss: 0.21582379937171936 | MAE Test Loss: 0.2866823077201843 \n",
      "Epoch: 40 | MAE Train Loss: 0.20695090293884277 | MAE Test Loss: 0.2546616196632385 \n",
      "Epoch: 50 | MAE Train Loss: 0.18511097133159637 | MAE Test Loss: 0.23452866077423096 \n",
      "Epoch: 60 | MAE Train Loss: 0.17621785402297974 | MAE Test Loss: 0.2284967005252838 \n",
      "Epoch: 70 | MAE Train Loss: 0.18369396030902863 | MAE Test Loss: 0.22306446731090546 \n",
      "Epoch: 80 | MAE Train Loss: 0.1892288476228714 | MAE Test Loss: 0.2310035526752472 \n",
      "Epoch: 90 | MAE Train Loss: 0.1819477677345276 | MAE Test Loss: 0.21811088919639587 \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs (how many times the model will pass over the training data)\n",
    "epochs = 100\n",
    "\n",
    "# Create empty loss lists to track values\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "\n",
    "    model_0.train()                    # Put model in training mode (this is the default state of a model)\n",
    "\n",
    "    y_pred = model_0(trainX)           # 1. Forward pass on train data using the forward() method inside \n",
    "    loss = loss_fn(y_pred, trainY)     # 2. Calculate the loss (how different are our models predictions to the ground truth)    \n",
    "    optimizer.zero_grad()              # 3. Zero grad (Reset) of the optimizer\n",
    "    loss.backward()                    # 4. Loss backwards\n",
    "    optimizer.step()                   # 5. Progress the optimizer\n",
    "\n",
    "    \n",
    "    \n",
    "    ### Testing\n",
    "    \n",
    "    model_0.eval()                     # Put the model in evaluation mode\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      test_pred = model_0(testX)                                  # 1. Forward pass on test data\n",
    "      test_loss = loss_fn(test_pred, testY.type(torch.float))     # 2. Caculate loss on test data\n",
    "    \n",
    "      # Print out what's happening\n",
    "      if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6919ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2708],\n",
       "        [0.2662],\n",
       "        [1.6153],\n",
       "        [1.8089],\n",
       "        [2.0821],\n",
       "        [1.5300],\n",
       "        [1.2739],\n",
       "        [1.8654],\n",
       "        [1.3508],\n",
       "        [0.3125]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3275a702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8000],\n",
       "        [0.2000],\n",
       "        [1.7000],\n",
       "        [2.0000],\n",
       "        [2.3000],\n",
       "        [1.5000],\n",
       "        [1.0000],\n",
       "        [2.3000],\n",
       "        [1.2000],\n",
       "        [0.2000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97cda2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving PyTorch Models\n",
    "#    - torch.nn.Module.load_state_dict (Recommended)\n",
    "#    - torch.save (Pickle)\n",
    "#    - torch.load (Pickle)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory \n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path \n",
    "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict \n",
    "torch.save(obj=model_0.state_dict(),f=MODEL_SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e038a357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading PyTorch Models\n",
    "\n",
    "loaded_model_0 = LinearRegression()\n",
    "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2181bc46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
